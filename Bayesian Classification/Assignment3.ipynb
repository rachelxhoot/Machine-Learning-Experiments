{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第三题：实现带有拉普拉斯修正的朴素贝叶斯(选做）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验内容：\n",
    "1. 叙述拉普拉斯修正的作用\n",
    "2. 给出使用的数据集\n",
    "3. 给出实现的代码，要有详细的注释\n",
    "4. 给出模型评价指标的结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.拉普拉斯修正的作用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**拉普拉斯修正的含义：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在训练集中总共的分类数用 N 表示；di 属性可能的取值数用 Ni 表示，因此原来的先验概率 P(c) 的计算公式由："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(c)=\\frac{D_c}{D}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "被拉普拉斯修正为："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(c)=\\frac{D_c +1}{D+N}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "类的条件概率P(x|c) 的计算公式由："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(x_i |c)=\\frac{D_{c,x_i}}{D_c} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "被拉普拉斯修正为："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(x_i |c)=\\frac{D_{c,x_i}+1}{D_c +Ni} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由上，拉普拉斯修正的作用是：\n",
    "- **避免其他属性携带的信息被训练集中未出现的属性值抹去。**\n",
    "- 在离散属性任务中，由于是直接将频率当成概率，所以若一个属性未出现，则计算出的概率始终0，为了避免这种错误，可以使用拉普拉斯修正使之平滑。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.给出使用的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "spambase = np.loadtxt('spambase/spambase.data', delimiter = \",\")\n",
    "spamx = spambase[:, :57]\n",
    "spamy = spambase[:, 57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讲spamx数据类型转换为float64\n",
    "spamx_binary = (spamx != 0).astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分割数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainX, testX, trainY, testY = train_test_split(spamx_binary, spamy, test_size = 0.4, random_state = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.带有拉普拉斯修正的朴素贝叶斯实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Laplace:\n",
    "    '''\n",
    "    处理二值特征的高斯朴素贝叶斯（拉普拉斯平滑）\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        初始化四个字典\n",
    "        self.label_mapping     类标记 与 下标(int)\n",
    "        self.probability_of_y  类标记 与 先验概率(float)\n",
    "        self.mean              类标记 与 均值(np.ndarray)\n",
    "        self.var               类标记 与 方差(np.ndarray)\n",
    "        '''\n",
    "        self.label_mapping = dict()\n",
    "        self.probability_of_y = dict()\n",
    "        self.mean = dict()\n",
    "        self.var = dict()\n",
    "        \n",
    "    def _clear(self):\n",
    "        '''\n",
    "        为了防止一个实例反复的调用fit方法，我们需要每次调用fit前，将之前学习到的参数删除掉\n",
    "        '''\n",
    "        self.label_mapping.clear()\n",
    "        self.probability_of_y.clear()\n",
    "        self.mean.clear()\n",
    "        self.var.clear()\n",
    "    \n",
    "    def fit(self, trainX, trainY):\n",
    "        '''\n",
    "        这里，我们要根据trainY内的类标记，针对每类，计算这类的先验概率，以及这类训练样本每个特征的均值和方差\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            trainX: np.ndarray, 训练样本的特征, 维度：(样本数, 特征数)\n",
    "        \n",
    "            trainY: np.ndarray, 训练样本的标记, 维度：(样本数, )\n",
    "        '''\n",
    "        \n",
    "        # 先调用_clear\n",
    "        self._clear()\n",
    "        \n",
    "        # 获取类标记\n",
    "        labels = np.unique(trainY)\n",
    "        \n",
    "        # 添加类标记与下标的映射关系\n",
    "        self.label_mapping = {label: index for index, label in enumerate(labels)}\n",
    "        \n",
    "        # 遍历每个类\n",
    "        for label in labels:\n",
    "            \n",
    "            # 取出为label这类的所有训练样本，存为 x\n",
    "            x = trainX[trainY == label, :]\n",
    "            \n",
    "            # 计算先验概率，用 x 的样本个数除以训练样本总个数，存储到 self.probability_of_y 中，键为 label，值为先验概率\n",
    "            # YOUR CODE HERE\n",
    "            self.probability_of_y[label] = (x.shape[0]+1)/ (trainX.shape[0]+labels.shape[0])\n",
    "            \n",
    "        \n",
    "    def predict(self, testX):\n",
    "        '''\n",
    "        给定测试样本，预测测试样本的类标记，这里我们要实现化简后的公式\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            testX: np.ndarray, 测试的特征, 维度：(测试样本数, 特征数)\n",
    "    \n",
    "        Returns\n",
    "        ----------\n",
    "            prediction: np.ndarray, 预测结果, 维度：(测试样本数, )\n",
    "        '''\n",
    "        \n",
    "        # 初始化一个空矩阵 results，存储每个样本属于每个类的概率，维度是 (测试样本数，类别数)，每行表示一个样本，每列表示一个特征\n",
    "        results = np.empty((testX.shape[0], len(self.probability_of_y)))\n",
    "        \n",
    "        # 初始化一个列表 labels，按 self.label_mapping 的映射关系存储所有的标记，一会儿会在下面的循环内部完成存储\n",
    "        labels = [0] * len(self.probability_of_y)\n",
    "        \n",
    "        # 遍历当前的类，label为类标记，index为下标，我们将每个样本预测出来的这个 label 的概率，存到 results 中的第 index 列\n",
    "        for label, index in self.label_mapping.items():\n",
    "            \n",
    "            # 先验概率存为 py\n",
    "            py = self.probability_of_y[label]\n",
    "            \n",
    "            # 使用变换后的公式，计算所有特征的条件概率之和，存为sum_of_conditional_probability\n",
    "            # YOUR CODE HERE\n",
    "            # 这里 还没有 实现！！！\n",
    "            sum_of_conditional_probability = - 0.5 * np.sum(np.power((testX - self.mean[label]),2) / self.var[label], axis = 1)- 0.5 * np.sum(np.log(2 * np.pi * self.var[label]))\n",
    "                                            \n",
    "            # debug\n",
    "            assert sum_of_conditional_probability.shape == (len(testX), )\n",
    "            \n",
    "            # 使用变换后的公式，将 条件概率 与 log先验概率 相加，存为result，维度应该是 (测试样本数, )\n",
    "            # YOUR CODE HERE\n",
    "            result = sum_of_conditional_probability+np.log(py)\n",
    "            \n",
    "            # debug\n",
    "            assert result.shape == (len(testX), )\n",
    "            \n",
    "            # 将所有测试样本属于当前这类的概率，存入到results中\n",
    "            results[:, index] = result\n",
    "            \n",
    "            # 将当前的label，按index顺序放入到labels中\n",
    "            labels[index] = label\n",
    "        \n",
    "        # 将labels转换为np.ndarray\n",
    "        np_labels = np.array(labels)\n",
    "        \n",
    "        # 循环结束后，就计算出了给定测试样本，当前样本属于这类的概率的近似值，存放在了results中，每行对应一个样本，每列对应一个特征\n",
    "        # 我们要求每行的最大值对应的下标，也就是求每个样本，概率值最大的那个下标是什么，结果存入max_prob_index中\n",
    "        # YOUR CODE HERE\n",
    "        max_prob_index = np.argmax(results, axis=1)\n",
    "        \n",
    "        # debug\n",
    "        assert max_prob_index.shape == (len(testX), )\n",
    "        \n",
    "        # 现在得到了每个样本最大概率对应的下标，我们需要把这个下标变成 np_labels 中的标记\n",
    "        # 使用上面小技巧中的第五点求解\n",
    "        # YOUR CODE HERE\n",
    "        prediction = np_labels[max_prob_index]\n",
    "        \n",
    "        # debug\n",
    "        assert prediction.shape == (len(testX), )\n",
    "        \n",
    "        # 返回预测结果\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Laplace()\n",
    "model.fit(trainX, trainY)\n",
    "\n",
    "prediction = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(testY, prediction)\n",
    "pre = precision_score(testY, prediction)\n",
    "rec = recall_score(testY, prediction)\n",
    "f1 = f1_score(testY, prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
